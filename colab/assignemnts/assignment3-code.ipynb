{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Homework\n",
        "1) Write your own function to compute the **confusion matrix** and the **diagonal** with the classification scores for each class."
      ],
      "metadata": {
        "id": "Fs9cs-HWZpVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_confusion_matrix(test_y, pred_y):\n",
        "  classes = np.unique(test_y)\n",
        "  confmat = np.zeros((len(classes), len(classes)))\n",
        "  for i in range(len(classes)):\n",
        "    for j in range(len(classes)):\n",
        "       confmat[i, j] = np.sum((test_y == classes[i]) & (pred_y == classes[j]))\n",
        "\n",
        "  return confmat, (confmat.diagonal() / confmat.sum(axis=1))"
      ],
      "metadata": {
        "id": "asK_hOxPZrr8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Download the CIFAR 10 dataset from Virtuale (`CIFAR-10-simple.zip`).\n",
        "Load the dataset and the classes, try to solve the classification problem. You can use only the data provided in the `train` folder to train your model.\n",
        "Compute the final accuracy with the folder `test`.\n",
        "\n",
        "CIFAR 10 (https://www.cs.toronto.edu/~kriz/cifar.html) consists in **32x32 colour images** (RGB) divided in **10 classes**. There are **300 samples in training** and **50 testing samples** for each class.\n",
        "\n",
        "Upload your result (`results.txt`) on Virtuale, including the classifier(s) and features used. The student with best accuracy will present his/her solution in the next lecture!\n"
      ],
      "metadata": {
        "id": "tt08FF_XZwyS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "tnVplOvG-wNj"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import os\n",
        "import sklearn\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "from os.path import join\n",
        "import cv2\n",
        "from skimage.feature import hog, local_binary_pattern\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1821)"
      ],
      "metadata": {
        "id": "aXBk423k_AqT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data"
      ],
      "metadata": {
        "id": "8vQVWeIl_CRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q CIFAR-10-simple.zip -d /content"
      ],
      "metadata": {
        "id": "0TliPADe_EzN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image, ImageEnhance"
      ],
      "metadata": {
        "id": "pGIqm44h16Az"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path_test = '/content/CIFAR-10-simple/test'\n",
        "dataset_path_train = '/content/CIFAR-10-simple/train'\n",
        "\n",
        "test_set = glob(join(dataset_path_test, '*', '*.jpg'))\n",
        "train_set = glob(join(dataset_path_train, '*', '*.jpg'))\n",
        "\n",
        "print('Test set: ', len(test_set))\n",
        "print('Train set: ', len(train_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUFgVKd_BWkP",
        "outputId": "b3e444ff-7c41-424e-ffe9-5f1223a0c525"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CIFAR-10-simple/train/deer/0010.jpg\n",
            "/content/CIFAR-10-simple/train/dog/0206.jpg\n",
            "/content/CIFAR-10-simple/train/bird/0112.jpg\n",
            "Test set:  500\n",
            "Train set:  3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prova = train_set[100]\n",
        "\n",
        "img = cv2.imread(prova)\n",
        "\n",
        "alpha = 2 # Contrast control (1.0-3.0)\n",
        "beta = -80 # Brightness control (0-100)\n",
        "\n",
        "adjusted = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
        "cv2_imshow(adjusted)\n",
        "\n",
        "diff = cv2.imread(prova)\n",
        "cv2_imshow(diff)\n",
        "# cv2.imwrite('contrast_board.jpg', adapt_thresh)\n",
        "# cv2.waitKey(0)\n",
        "# cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "aomTyWhX6zgY",
        "outputId": "00a2f75e-59fb-45bf-b0df-8cca8709024f"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FE6D31AD850>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FE6D31ADED0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Labels:\n",
        "- Airplane: 0\n",
        "- Automobile: 1\n",
        "- Bird: 2\n",
        "- Cat: 3\n",
        "- Deer: 4\n",
        "- Dog: 5\n",
        "- Frog: 6\n",
        "- Horse: 7\n",
        "- Ship: 8\n",
        "- Truck 9"
      ],
      "metadata": {
        "id": "kWS1wY4-Nb_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_labels(image):\n",
        "  if 'airplane' in image:\n",
        "    return 0\n",
        "  elif 'automobile' in image:\n",
        "    return 1\n",
        "  elif 'bird' in image:\n",
        "    return 2\n",
        "  elif 'cat' in image:\n",
        "    return 3\n",
        "  elif 'deer' in image:\n",
        "    return 4\n",
        "  elif 'dog' in image:\n",
        "    return 5\n",
        "  elif 'frog' in image:\n",
        "    return 6\n",
        "  elif 'horse' in image:\n",
        "    return 7\n",
        "  elif 'ship' in image:\n",
        "    return 8\n",
        "  elif 'truck' in image:\n",
        "    return 9\n",
        "  else:\n",
        "    raise NotImplementedError('Not existing class!')"
      ],
      "metadata": {
        "id": "29k0C4EeMRtv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract Features with BW images"
      ],
      "metadata": {
        "id": "wUrLaFUDOxYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(images, feat_type, img_size):\n",
        "\n",
        "    labels = []\n",
        "    features = []\n",
        "\n",
        "    for image in tqdm(images):\n",
        "\n",
        "        # open the image\n",
        "        img = cv2.imread(image, 0)\n",
        "\n",
        "        # resize the image\n",
        "        img = cv2.resize(img, (img_size, img_size))\n",
        "\n",
        "        # compute the features\n",
        "        if feat_type == 'hog':\n",
        "            feat = hog(img, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2))\n",
        "        elif feat_type == 'lbp':\n",
        "            feat = np.ravel(local_binary_pattern(img, P=100, R=5))\n",
        "        elif feat_type == 'img':\n",
        "            img = img / 256.0\n",
        "            feat = np.ravel(img)\n",
        "        else:\n",
        "            raise NotImplementedError('Not implemented feature!')\n",
        "\n",
        "        # append features and labels\n",
        "        features.append(feat)\n",
        "        labels.append(get_labels(image))\n",
        "\n",
        "    return features, labels"
      ],
      "metadata": {
        "id": "FAIEdN7dXZ_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample Distribution:\n",
        "- Train: 76%\n",
        "- Test: 14%\n",
        "- Validation: 10%\n"
      ],
      "metadata": {
        "id": "of7JnHyDSTcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.shuffle(test_set)\n",
        "np.random.shuffle(train_set)\n",
        "trainset = train_set[350:]\n",
        "valset = train_set[0:350]\n",
        "testset = test_set\n",
        "print('Total: {} splitted in Train: {}, Val: {} and Test: {}'.format(len(train_set) + len(test_set), len(trainset), len(valset), len(testset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajlIMEu9QZEj",
        "outputId": "3bd05b60-4de7-4ef5-f9c8-5a254e33ff4a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total: 3500 splitted in Train: 2650, Val: 350 and Test: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "size = [\n",
        "    32,\n",
        "    64,\n",
        "    128\n",
        "]\n",
        "\n",
        "features = [\n",
        "    'hog',\n",
        "    'lbp',\n",
        "    'img'\n",
        "]\n",
        "\n",
        "for size in size:\n",
        "  for feature in features:\n",
        "    t1 = time.time()\n",
        "    train_x, train_y = extract_features(trainset, feature, size)\n",
        "    val_x, val_y = extract_features(valset, feature, size)\n",
        "    test_x, test_y = extract_features(testset, feature, size)\n",
        "    clf = svm.SVC(gamma=0.001, C=100., kernel='rbf', verbose=False)\n",
        "    clf.fit(train_x, train_y)\n",
        "    clf.score(val_x, val_y)\n",
        "    y_pred = clf.predict(test_x)\n",
        "    t2 = time.time()\n",
        "    print()\n",
        "    print('Final Accuracy {} {}: {:.3f} - Elapsed Time: {}'.format((feature),(size),(accuracy_score(test_y, y_pred)),(t2 - t1)))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "SCBEZ7tQPoDz",
        "outputId": "4c38386a-e9a2-4a92-eb28-d8adfd6f2297"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-e6766605b900>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'extract_features' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HOG seems to be the most accurate feature descriptor (compared to LBP and np.ravel), therefore, we will check the accuracy of HOG using different classifiers:\n",
        "\n",
        "- SVC\n",
        "- Random Forest\n",
        "- Ada Boost\n",
        "- Decision Tree\n",
        "- Quadratic Discrimination"
      ],
      "metadata": {
        "id": "zmDMTpuiNXf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from PIL import Image, ImageEnhance"
      ],
      "metadata": {
        "id": "fMqugqM_r0gn"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prova = train_set[100]\n",
        "\n",
        "img = cv2.imread(prova)\n",
        "\n",
        "alpha = 1.5 # Contrast control (1.0-3.0)\n",
        "beta = -80 # Brightness control (0-100)\n",
        "\n",
        "adjusted = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
        "cv2_imshow(adjusted)\n",
        "\n",
        "diff = cv2.imread(prova)\n",
        "cv2_imshow(diff)\n",
        "# cv2.imwrite('contrast_board.jpg', adapt_thresh)\n",
        "# cv2.waitKey(0)\n",
        "# cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "EJkSdtQlBtku",
        "outputId": "f203037d-747d-416e-c23a-b73ae31ccddd"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FE6D2F25D10>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7FE6D2F25CD0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To achieve a higher accuracy, the **contrast** of each image has been improved by 1.5 while **brightness** has been diminished by -80.\n",
        "\n",
        "It seems that BGR images achieve a higher accuracy compared to BW images (with modified contrast and brightness)."
      ],
      "metadata": {
        "id": "n3dm2204B4N7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_hog(images, img_size):\n",
        "\n",
        "    labels = []\n",
        "    features = []\n",
        "\n",
        "    for image in (images):\n",
        "\n",
        "        img_init = cv2.imread(image) #(image, 0) -> bw\n",
        "\n",
        "        alpha = 1.5 # Contrast control (1.0-3.0)\n",
        "        beta = -80 # Brightness control (0-100)\n",
        "\n",
        "        adjusted = cv2.convertScaleAbs(img_init, alpha=alpha, beta=beta)\n",
        "\n",
        "        # open the image\n",
        "        # img = cv2.imread(image, 0)\n",
        "\n",
        "        # resize the image\n",
        "        img = cv2.resize(adjusted, (img_size, img_size))\n",
        "\n",
        "        # increase contrast\n",
        "        # img2 = ImageEnhance.Contrast(img)\n",
        "\n",
        "        # compute the feature\n",
        "        feat = hog(img, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), multichannel=True)\n",
        "\n",
        "        # append features and labels\n",
        "        features.append(feat)\n",
        "        labels.append(get_labels(image))\n",
        "\n",
        "    return features, labels"
      ],
      "metadata": {
        "id": "RprnuWihONr6"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.arrayprint import format_float_scientific\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
      ],
      "metadata": {
        "id": "Hc4iCuj7O4zf"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size = [\n",
        "    32,\n",
        "    64,\n",
        "    128\n",
        "]\n",
        "\n",
        "names = [\n",
        "    \"SVC\",\n",
        "    \"Random Forest\",\n",
        "    \"Ada Boost\",\n",
        "    \"Decision Tree\",\n",
        "    \"Quadratic Discrimination\"\n",
        "]\n",
        "\n",
        "classifiers = [\n",
        "    svm.SVC(gamma=0.001, C=100., kernel='rbf', verbose=False, probability=False),\n",
        "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "    AdaBoostClassifier(),\n",
        "    DecisionTreeClassifier(),\n",
        "    QuadraticDiscriminantAnalysis()\n",
        "]\n",
        "\n",
        "for size in size:\n",
        "  for name, clf in zip(names, classifiers):\n",
        "    t1 = time.time()\n",
        "    train_x, train_y = apply_hog(trainset, size)\n",
        "    val_x, val_y = apply_hog(valset, size)\n",
        "    test_x, test_y = apply_hog(testset, size)\n",
        "    clf.fit(train_x, train_y)\n",
        "    clf.score(val_x, val_y)\n",
        "    y_pred = clf.predict(test_x)\n",
        "    t2 = time.time()\n",
        "    print()\n",
        "    print('Elapsed Time: {}'.format((t2 - t1)))\n",
        "    print('Final accuracy: {} {}, {:.3f}'.format((name),(size),(accuracy_score(test_y, y_pred))))   \n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        },
        "id": "M923g9VCOodo",
        "outputId": "89781a7c-97d0-4260-d134-1b56aae37968"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Elapsed Time: 5.32557225227356\n",
            "Final accuracy: SVC 32, 0.412\n",
            "\n",
            "\n",
            "Elapsed Time: 3.2331478595733643\n",
            "Final accuracy: Random Forest 32, 0.274\n",
            "\n",
            "\n",
            "Elapsed Time: 9.675410985946655\n",
            "Final accuracy: Ada Boost 32, 0.290\n",
            "\n",
            "\n",
            "Elapsed Time: 4.276067018508911\n",
            "Final accuracy: Decision Tree 32, 0.200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Elapsed Time: 3.5812225341796875\n",
            "Final accuracy: Quadratic Discrimination 32, 0.120\n",
            "\n",
            "\n",
            "Elapsed Time: 18.77253818511963\n",
            "Final accuracy: SVC 64, 0.414\n",
            "\n",
            "\n",
            "Elapsed Time: 9.988600254058838\n",
            "Final accuracy: Random Forest 64, 0.246\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-152-16036b46e66f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_hog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_hog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# Boosting step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             sample_weight, estimator_weight, estimator_error = self._boost(\n\u001b[0;32m--> 146\u001b[0;31m                 \u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             )\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \"\"\"\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"SAMME.R\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m         )\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Decision Tree** classifier and the **Quadratic Discrimination** classifier provide the lowest accuracy score.\n",
        "\n",
        "On the other hand, **SVC** is the most accurate, followed by **Ada Boost** and **Random Forest**.\n",
        "\n",
        "Now, we will try to optimize these classifiers:"
      ],
      "metadata": {
        "id": "Gi41NdVXUc2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = svm.SVC(gamma='scale', C=100., kernel='rbf', verbose=False, probability=False)\n",
        "size = [32, 64, 128]\n",
        "\n",
        "for size in size:\n",
        "  t1 = time.time()\n",
        "  train_x, train_y = apply_hog(trainset, size)\n",
        "  val_x, val_y = apply_hog(valset, size)\n",
        "  test_x, test_y = apply_hog(testset, size)\n",
        "  clf.fit(train_x, train_y)\n",
        "  clf.score(val_x, val_y)\n",
        "  y_pred = clf.predict(test_x)\n",
        "  t2 = time.time()\n",
        "  print()\n",
        "  print('Elapsed Time: {}'.format((t2 - t1)))\n",
        "  print('Final accuracy: {} {}, {:.3f}'.format((name),(size),(accuracy_score(test_y, y_pred))))   \n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iEw9kFoc5fi",
        "outputId": "59af93e5-38c6-4984-9cd5-a1d072e37e22"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Elapsed Time: 5.862117290496826\n",
            "Final accuracy: SVC 32, 0.478\n",
            "\n",
            "\n",
            "Elapsed Time: 23.638479232788086\n",
            "Final accuracy: SVC 64, 0.486\n",
            "\n",
            "\n",
            "Elapsed Time: 129.62877583503723\n",
            "Final accuracy: SVC 128, 0.440\n",
            "\n"
          ]
        }
      ]
    }
  ]
}