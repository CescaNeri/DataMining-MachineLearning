{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Classification with Machine Learning**\n",
        "\n",
        "In this lesson, we learn how to solve a classification problem through Machine Learning classifiers, *i.e.* model that are able to automatically learn how to solve a problem.\n",
        "\n",
        "**It is absolutely recommended to read the documentation relating to the functions and methods used!**\n",
        "Usually, it is sufficient typing on Google the name of the function (and eventually the name of the library used)."
      ],
      "metadata": {
        "id": "wFjJxN88-_Xw"
      },
      "id": "wFjJxN88-_Xw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import some libraries\n",
        "In particular, `sklearn` is the library for the Machine Learning stuff!"
      ],
      "metadata": {
        "id": "FQx0egnB_ZTb"
      },
      "id": "FQx0egnB_ZTb"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d39427db-e6d8-49d0-a395-6d96344edaba",
      "metadata": {
        "id": "d39427db-e6d8-49d0-a395-6d96344edaba"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions and Classes\n",
        "This is the class that we'll use to handle coordinates of the dataset. We assume to work with only 2D $(x,y)$  coordinates."
      ],
      "metadata": {
        "id": "jKOGvTBK_dPb"
      },
      "id": "jKOGvTBK_dPb"
    },
    {
      "cell_type": "code",
      "source": [
        "class Point:\n",
        "    x = None\n",
        "    y = None"
      ],
      "metadata": {
        "id": "QHoO8Wi6QWmv"
      },
      "id": "QHoO8Wi6QWmv",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`get_labels()` is a function that receives a name (`string`) and returns the class (`int`), following this:\n",
        "\n",
        "*   Triangle: 0\n",
        "*   Rectangle: 1\n",
        "*   Square: 2\n",
        "*   Rhombus: 3\n",
        "\n",
        "Example: 0_triangle.png → 0"
      ],
      "metadata": {
        "id": "xI3jL4Kd_ksT"
      },
      "id": "xI3jL4Kd_ksT"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_labels(name):\n",
        "    if 'triangle' in name:\n",
        "        return 0\n",
        "    elif 'square' in name:\n",
        "        return 1\n",
        "    elif 'rectangle' in name:\n",
        "        return 2\n",
        "    elif 'rhombus' in name:\n",
        "        return 3\n",
        "    else:\n",
        "        raise NotImplementedError('Not existing class!')"
      ],
      "metadata": {
        "id": "vJitaZqSPjXR"
      },
      "id": "vJitaZqSPjXR",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`prepare__data()` is a function that prepare the data for the computation. \n",
        "Specifically, returns two lists: `coordinates` and `labels`.\n",
        "In this exercise, we exclude `triangles` from classes for simplicity."
      ],
      "metadata": {
        "id": "FGN5pf8jAtJU"
      },
      "id": "FGN5pf8jAtJU"
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(lines):\n",
        "    labels = []\n",
        "    coordinates = []\n",
        "\n",
        "    for line in lines:\n",
        "        content = line.split()\n",
        "\n",
        "        # let's exclude triangles\n",
        "        if 'triangle' not in content[0]:\n",
        "            # create label\n",
        "            labels.append(get_labels(content[0]))\n",
        "\n",
        "            # coordinates\n",
        "            coordinates.append([float(x) for x in content[1:]])\n",
        "    \n",
        "    return coordinates, labels"
      ],
      "metadata": {
        "id": "NXxyK0sRPmOW"
      },
      "id": "NXxyK0sRPmOW",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_euclidean_distance(p1, p2):\n",
        "    return math.sqrt((p1.x - p2.x)**2 + ((p1.y - p2.y)**2))"
      ],
      "metadata": {
        "id": "tx9cvvP7BL0r"
      },
      "id": "tx9cvvP7BL0r",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Body of the solution\n",
        "Upload the file `shapes.txt`.\n",
        "Open the dataset file `shapes.txt` and read the content"
      ],
      "metadata": {
        "id": "zM7mgZQxBub7"
      },
      "id": "zM7mgZQxBub7"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_file_path = 'shapes.txt'\n",
        "with open(dataset_file_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    print('Read {} lines'.format(len(lines)))"
      ],
      "metadata": {
        "id": "F9UfwAokQcMJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e186260-c2af-473b-d68d-dc98291093e4"
      },
      "id": "F9UfwAokQcMJ",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 800 lines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We **shuffle** the data to change the initial order. \n",
        "It is important in order to have a train and a validation set with all classes.\n",
        "\n",
        "**Tools**:\n",
        "-    `np.random.shuffle()`: modify a sequence in-place by shuffling its contents."
      ],
      "metadata": {
        "id": "nL_HkwmsCCQ0"
      },
      "id": "nL_HkwmsCCQ0"
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.shuffle(lines)"
      ],
      "metadata": {
        "id": "SXKiO_paQjI4"
      },
      "id": "SXKiO_paQjI4",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Differently from the previous exercitation, **in this case it is essential to have a training and a validation sets**.\n",
        "Training data are used to train the model, while the validation (test) split is used to assess performance.\n",
        "\n",
        "Here, we use validation and test set as synonymous, since we do not have a real test set.\n",
        "\n",
        "We put **70% of data in training, 10% in validation**, and the remaining **20% in the test set**."
      ],
      "metadata": {
        "id": "wKpyTz4HCLcC"
      },
      "id": "wKpyTz4HCLcC"
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = lines[:int(0.2*len(lines))]\n",
        "valset = lines[int(0.2*len(lines)):int(0.4*len(lines))]\n",
        "testset = lines[int(0.4*len(lines)):]\n",
        "print('Total: {} splitted in Train: {}, Val: {} and Test: {}'.format(len(lines), len(trainset), len(valset), len(testset)))"
      ],
      "metadata": {
        "id": "fipgi_u-QnlP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3954ca7-b1d5-4755-c214-bfc6e089aa02"
      },
      "id": "fipgi_u-QnlP",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total: 800 splitted in Train: 160, Val: 160 and Test: 480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this moment, we will have three sets: train, validation and test set. \n",
        "\n",
        "A single datapoint belongs only to one, **these three sets are completely disjointed**.\n",
        "\n",
        "It is important to keep them separated!"
      ],
      "metadata": {
        "id": "4x4XwcitCwig"
      },
      "id": "4x4XwcitCwig"
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, train_y = prepare_data(trainset)\n",
        "val_x, val_y = prepare_data(valset)\n",
        "test_x, test_y = prepare_data(testset)\n",
        "print('Train: {}, Val: {} and Test: {}'.format(len(train_x), len(val_x), len(test_x)))"
      ],
      "metadata": {
        "id": "SbKcMlOWQtTn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8b6dd68-eb5c-439d-a504-59e42c2b2690"
      },
      "id": "SbKcMlOWQtTn",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 160, Val: 160 and Test: 480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classifier\n",
        "Here, we define what classifier we are going to use to solve our classification problem. Let's use the SVM implementation of the `sklearn` library.\n"
      ],
      "metadata": {
        "id": "u1My56AGDIXj"
      },
      "id": "u1My56AGDIXj"
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(lines):\n",
        "    labels = []\n",
        "    coordinates = []\n",
        "\n",
        "    for line in lines:\n",
        "        content = line.split()\n",
        "\n",
        "        if 'triangle' in content[0]:\n",
        "          labels.append(get_labels(content[0]))\n",
        "          coord = [float(x) for x in content[1:]]\n",
        "          sumx = []\n",
        "          sumy = []\n",
        "          for value in range(len(coord)):\n",
        "            if value%2 == 0:\n",
        "              sumx.append(coord[value])\n",
        "            else:\n",
        "              sumy.append(coord[value])\n",
        "          coord.append(round(sum(sumx)/3))\n",
        "          coord.append(round(sum(sumy)/3))\n",
        "          coordinates.append(coord)\n",
        "\n",
        "        \n",
        "        # let's exclude triangles\n",
        "        elif 'triangle' not in content[0]:\n",
        "            # create label\n",
        "            labels.append(get_labels(content[0]))\n",
        "\n",
        "            # coordinates\n",
        "            coordinates.append([float(x) for x in content[1:]])\n",
        "    \n",
        "    return coordinates, labels"
      ],
      "metadata": {
        "id": "aoLyKrHyxq7k"
      },
      "id": "aoLyKrHyxq7k",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.arrayprint import format_float_scientific\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "names = [\n",
        "    \"SVC\",\n",
        "    \"Random Forest\",\n",
        "    \"Ada Boost\",\n",
        "    \"Decision Tree\",\n",
        "    \"Quadratic Discrimination\"\n",
        "]\n",
        "\n",
        "classifiers = [\n",
        "    svm.SVC(gamma=0.001, C=100., kernel='rbf', verbose=False, probability=False),\n",
        "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "    AdaBoostClassifier(),\n",
        "    DecisionTreeClassifier(),\n",
        "    QuadraticDiscriminantAnalysis()\n",
        "]\n",
        "\n",
        "for name, clf in zip(names, classifiers):\n",
        "  score = clf.fit(train_x, train_y)\n",
        "\n",
        "  print('Validation accuracy: {}, {:.3f}'.format((name),(clf.score(val_x, val_y))))\n",
        "  pred_y = clf.predict(test_x)\n",
        "  print('Final Accuracy: {:.3f}'.format(accuracy_score(test_y, pred_y)))\n",
        "\n"
      ],
      "metadata": {
        "id": "ZF5xpgPfQ36w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15be2938-0e1d-4420-8ebc-a1a1129cb96c"
      },
      "id": "ZF5xpgPfQ36w",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy: SVC, 0.588\n",
            "Final Accuracy: 0.621\n",
            "Validation accuracy: Random Forest, 0.725\n",
            "Final Accuracy: 0.702\n",
            "Validation accuracy: Ada Boost, 0.588\n",
            "Final Accuracy: 0.588\n",
            "Validation accuracy: Decision Tree, 0.700\n",
            "Final Accuracy: 0.758\n",
            "Validation accuracy: Quadratic Discrimination, 1.000\n",
            "Final Accuracy: 1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training\n",
        "Now we are ready for the training!\n",
        "With `sklearn` library is tremendously simple, we just need training data (`train_x` and the related labels `train_y`) and pass them to the classifier.\n",
        "\n",
        "**Tools**:\n",
        "-   `model.fit()`: fit the provided model with training data."
      ],
      "metadata": {
        "id": "RLkeVCUxDcIl"
      },
      "id": "RLkeVCUxDcIl"
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(train_x, train_y)"
      ],
      "metadata": {
        "id": "uaoAX6iwQ5hd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b552b14-5a86-4869-9dcf-8f75c72852b7"
      },
      "id": "uaoAX6iwQ5hd",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuadraticDiscriminantAnalysis()"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation\n",
        "\n",
        "It's time to validate the trained model, in order to find proper hyperparameters. \n",
        "\n",
        "**Tools:** \n",
        "*   `score()`: evaluates the quality of a model’s predictions.\n",
        "\n"
      ],
      "metadata": {
        "id": "eNNuHP0_hHYb"
      },
      "id": "eNNuHP0_hHYb"
    },
    {
      "cell_type": "code",
      "source": [
        "print('Validation accuracy: {:.3f}'.format(clf.score(val_x, val_y)))"
      ],
      "metadata": {
        "id": "SmdAmrAfhKKi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b40969f6-7d50-422c-a98d-faf84dde9785"
      },
      "id": "SmdAmrAfhKKi",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test\n",
        "Now we are reading to use our classifier! The trained classifier outputs the labels (as defined above) for the classification task.\n",
        "\n",
        "Tools:\n",
        "  - `model.predict()`: predict the class of the given data."
      ],
      "metadata": {
        "id": "Tuyy2J6hE9V8"
      },
      "id": "Tuyy2J6hE9V8"
    },
    {
      "cell_type": "code",
      "source": [
        "pred_y = clf.predict(test_x)\n",
        "print('Predicted {} samples: {}'.format(len(pred_y), pred_y))\n",
        "print('GT {} samples: {}'.format(len(test_y), test_y))"
      ],
      "metadata": {
        "id": "_hDdyRVIQ99P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63a64a2d-b9a9-444c-dcc1-2cc826986a45"
      },
      "id": "_hDdyRVIQ99P",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted 365 samples: [1 2 2 1 1 2 3 2 2 3 3 1 3 2 3 2 3 2 3 1 1 2 1 2 2 2 2 3 3 3 1 1 2 2 2 3 2\n",
            " 1 3 1 1 1 2 2 1 3 1 2 1 2 2 3 1 1 2 1 2 2 2 2 3 3 1 2 3 2 3 3 2 1 1 3 2 1\n",
            " 3 3 1 3 1 1 1 1 3 2 3 1 1 1 3 1 1 3 3 3 3 1 3 3 1 2 3 2 1 3 1 3 1 3 3 3 1\n",
            " 3 1 3 1 3 2 2 2 2 1 2 1 2 3 3 1 1 2 3 3 3 2 2 2 1 2 3 2 2 2 1 2 2 3 3 1 3\n",
            " 1 2 1 1 1 1 2 2 1 2 1 2 1 2 2 2 3 3 2 1 3 1 1 3 1 1 2 1 2 2 2 1 3 1 3 1 2\n",
            " 1 2 3 3 2 2 1 2 3 3 1 2 2 1 3 2 1 3 1 3 2 3 3 2 1 2 3 2 1 3 1 3 2 3 2 3 3\n",
            " 2 1 3 1 1 3 3 2 2 1 1 2 3 1 3 3 1 3 1 3 2 2 3 1 2 3 2 3 2 3 3 3 1 2 3 1 3\n",
            " 1 3 1 3 3 2 1 3 3 1 2 3 2 2 1 3 3 2 1 1 3 1 1 2 2 3 2 3 3 2 1 3 3 2 1 1 2\n",
            " 1 1 2 2 1 3 2 3 1 1 2 1 3 3 1 1 2 1 2 2 2 1 1 1 3 3 3 3 1 1 2 3 3 2 1 1 2\n",
            " 1 2 3 3 1 3 3 3 1 3 2 1 3 2 3 1 3 1 3 2 1 3 1 3 1 1 2 2 1 2 3 3]\n",
            "GT 365 samples: [1, 2, 2, 1, 1, 2, 3, 2, 2, 3, 3, 1, 3, 2, 3, 2, 3, 2, 3, 1, 1, 2, 1, 2, 2, 2, 2, 3, 3, 3, 1, 1, 2, 2, 2, 3, 2, 1, 3, 1, 1, 1, 2, 2, 1, 3, 1, 2, 1, 2, 2, 3, 1, 1, 2, 1, 2, 2, 2, 2, 3, 3, 1, 2, 3, 2, 3, 3, 2, 1, 1, 3, 2, 1, 3, 3, 1, 3, 1, 1, 1, 1, 3, 2, 3, 1, 1, 1, 3, 1, 1, 3, 3, 3, 3, 1, 3, 3, 1, 2, 3, 2, 1, 3, 1, 3, 1, 3, 3, 3, 1, 3, 1, 3, 1, 3, 2, 2, 2, 2, 1, 2, 1, 2, 3, 3, 1, 1, 2, 3, 3, 3, 2, 2, 2, 1, 2, 3, 2, 2, 2, 1, 2, 2, 3, 3, 1, 3, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 3, 3, 2, 1, 3, 1, 1, 3, 1, 1, 2, 1, 2, 2, 2, 1, 3, 1, 3, 1, 2, 1, 2, 3, 3, 2, 2, 1, 2, 3, 3, 1, 2, 2, 1, 3, 2, 1, 3, 1, 3, 2, 3, 3, 2, 1, 2, 3, 2, 1, 3, 1, 3, 2, 3, 2, 3, 3, 2, 1, 3, 1, 1, 3, 3, 2, 2, 1, 1, 2, 3, 1, 3, 3, 1, 3, 1, 3, 2, 2, 3, 1, 2, 3, 2, 3, 2, 3, 3, 3, 1, 2, 3, 1, 3, 1, 3, 1, 3, 3, 2, 1, 3, 3, 1, 2, 3, 2, 2, 1, 3, 3, 2, 1, 1, 3, 1, 1, 2, 2, 3, 2, 3, 3, 2, 1, 3, 3, 2, 1, 1, 2, 1, 1, 2, 2, 1, 3, 2, 3, 1, 1, 2, 1, 3, 3, 1, 1, 2, 1, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 1, 1, 2, 3, 3, 2, 1, 1, 2, 1, 2, 3, 3, 1, 3, 3, 3, 1, 3, 2, 1, 3, 2, 3, 1, 3, 1, 3, 2, 1, 3, 1, 3, 1, 1, 2, 2, 1, 2, 3, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's time to understand the how good is the trained classifier.\n",
        "\n",
        "**Tools**:\n",
        "   * `accuracy_score()`: accuracy classification score. The set of labels predicted for a sample must exactly match the corresponding set of labels of GT."
      ],
      "metadata": {
        "id": "gCXwtZzSK9H0"
      },
      "id": "gCXwtZzSK9H0"
    },
    {
      "cell_type": "code",
      "source": [
        "print('Final Accuracy: {:.3f}'.format(accuracy_score(test_y, pred_y)))"
      ],
      "metadata": {
        "id": "ln0j7RcbQ_9k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "146a877e-5aec-4f1a-cbf8-18babd1391fe"
      },
      "id": "ln0j7RcbQ_9k",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Accuracy: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Presumably, you have obtained a lower performance w.r.t. the previous exercitation (based on PR), but rememeber that:\n",
        "- Now the model has **automatically learned** how to solve the classification problem;\n",
        "- The classification problem is quite simple, since we know how to classify geometric shapes. Then, we have a good level of a-priori knowledge."
      ],
      "metadata": {
        "id": "Hdut2Imz5y6A"
      },
      "id": "Hdut2Imz5y6A"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise/Homework\n",
        "\n",
        "1) Try to obtain the highest accuracy in classification!\n",
        "You can use:\n",
        "- Different **classifiers**:\n",
        "  *   Tree classifiers, Random Forest, AdaBoostClassifier, ...\n",
        "  *   You can also install other packages (for instance, `xgboost`)\n",
        "\n",
        "You can find a list of several classifiers available in scikit-learn  library  here: https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html).\n",
        "Remember to import the classifiers from sklearn package!\n",
        "\n",
        "- Different **data** in input (you can provide not only the raw coordinates of the shapes, but also other values like diagonals and so on). \n",
        "- Different **normalization** of data.\n",
        "- Different **data splits** (you can vary the amount of samples in train, val and test sets).\n",
        "\n",
        "**Data Normalization**\n",
        "The purpose of normalization is to transform data in a way that they have similar distributions. Normalization for instance translates data into the range [0, 1] or [-1, +1] as follows:\n",
        "\n",
        "> `coordinates = (coordinates - np.mean(coordinates)) / np.std(coordinates)`\n",
        "\n",
        "or\n",
        "\n",
        "> `coordinates = (coordinates - np.min(coordinates)) / (np.max(coordinates)-np.min(coordinates))`\n",
        "\n",
        "In our case, in the Euclid dataset all coordinates are already in the range [0, 224] and then normalization is not strictly needed (actually, in some cases decreases the final accuracy, since normalization compresses data within a certain range, reducing the variance).\n",
        "\n",
        "**NB** In order to obtain comparable results, do not shuffle again the dataset. Only modify the `prepare_data()` function, and/or define a new classifier, and then run a new `fit()` and `score()` procedure.\n",
        "\n",
        "2) Obtain prediction probabilities.\n",
        "\n",
        "**Tools:**\n",
        "*   `predict_proba()`: returns the class probabilities for each data point (model must have the parameter `probability` set to `True`!)\n",
        "\n",
        "3) Include also **triangles** in the classification problem.\n",
        "\n"
      ],
      "metadata": {
        "id": "YXeGC4cczmsQ"
      },
      "id": "YXeGC4cczmsQ"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}