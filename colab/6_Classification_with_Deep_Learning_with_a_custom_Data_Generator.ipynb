{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Classification with Deep Learning (CNNs) with a custom Data Generator\n",
        "\n",
        "In this lesson, we learn how to solve a classification problem through a **Deep Learning** approach based on *Convolutional Neural Networks* (CNNs) and a **custom data generator** to load the data. In the final part, we'll see how is possible to load a single image and **obtain the CNN prediction** (useful for real-worl applications).\n",
        "\n",
        "**It is absolutely recommended to read the documentation relating to the functions and methods used!**\n",
        "Usually, it is sufficient typing on Google the name of the function (and eventually the name of the library used)."
      ],
      "metadata": {
        "id": "qg7KL0aWQwJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's import some **libraries**. We will use *TensorFlow* and *Keras* as Deep Learning framework."
      ],
      "metadata": {
        "id": "ZssyrYnDRGmR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcH4Xacbg7bF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data\n",
        "\n",
        "\n",
        "1.   Upload the `.zip` file containing the *Euclid* dataset (Deep Learning version!) → this is for **training**\n",
        "2.   Unzip all files using the following commands. Dataset folders will appear in `/content`"
      ],
      "metadata": {
        "id": "SLXpysTPRVJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q Euclid_dataset_DL.zip -d /content"
      ],
      "metadata": {
        "id": "z6gGq9EshL37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Data Loader\n",
        "\n",
        "To define our **custom data loader**, we use the object `tf.keras.utils.Sequence`([link](https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence)).\n",
        "\n",
        "Every Sequence must implement the `__getitem__` and the `__len__` methods. If you want to modify your dataset between epochs you may implement `on_epoch_end`. The method `__getitem__` should return a complete batch.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GhllMIO4Rb3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "class CustomDataGen(tf.keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, data_list, num_classes, batch_size, input_size=(224, 224, 3), shuffle=True):\n",
        "\n",
        "        self.data_list = data_list\n",
        "        self.num_classes = num_classes\n",
        "        self.batch_size = batch_size\n",
        "        self.input_size = input_size\n",
        "        self.shuffle = shuffle\n",
        "        self.n = len(self.data_list)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.data_list)\n",
        "\n",
        "    # here, we get the input (load an image)\n",
        "    def __get_input(self, path, target_size):\n",
        "        img = cv2.imread(path, 1)\n",
        "        img = img[..., ::-1]\n",
        "        img = cv2.resize(img, (target_size[0], target_size[1]))\n",
        "        img = np.asarray(img, dtype=np.float32)\n",
        "        return img / 255.0\n",
        "\n",
        "    # here, we get the class number\n",
        "    def __get_class_number(self, name):\n",
        "        if 'triangle' in name:\n",
        "            return 0\n",
        "        elif 'square' in name:\n",
        "            return 1\n",
        "        elif 'rectangle' in name:\n",
        "            return 2\n",
        "        elif 'rhombus' in name:\n",
        "            return 3\n",
        "        else:\n",
        "            raise NotImplementedError('Not existing class!')\n",
        "\n",
        "    # here, we convert the class number in a one-hot vector (binary class matrix). Ex: 2 -> 0010, 4 -> 1000\n",
        "    def __get_label(self, item):\n",
        "        return tf.keras.utils.to_categorical(self.__get_class_number(item), num_classes=self.num_classes)\n",
        "\n",
        "    # here, we generate data containing batch_size samples\n",
        "    def __get_data(self, batches):\n",
        "        \n",
        "        # batch for input data (images)\n",
        "        x_batch = []\n",
        "        for item in batches:\n",
        "            img = self.__get_input(item, self.input_size)\n",
        "            x_batch.append(img)\n",
        "        x_batch = np.asarray(x_batch)\n",
        "\n",
        "        # batch for labels\n",
        "        y_batch = []\n",
        "        for item in batches:\n",
        "            label = self.__get_label(item)\n",
        "            y_batch.append(label)\n",
        "        y_batch = np.asarray(y_batch)\n",
        "\n",
        "        return x_batch, y_batch\n",
        "\n",
        "    # \"entry point\" of the code\n",
        "    def __getitem__(self, index):\n",
        "        batches = self.data_list[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        x, y = self.__get_data(batches)\n",
        "        return x, y\n",
        "\n",
        "    # the number of iterations to complete an epoch\n",
        "    def __len__(self):\n",
        "        return self.n // self.batch_size"
      ],
      "metadata": {
        "id": "goHMzLR-hBPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the custom generator, we have to define two lists:\n",
        "*   **Training list**: contains all paths of the training images\n",
        "*   **Validation list**: contains all paths of the validation images\n",
        "\n"
      ],
      "metadata": {
        "id": "Puopjun7NOEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "from os.path import join \n",
        "\n",
        "# read all images\n",
        "data_list = glob(join('/content/Euclid_dataset_DL', '*', '*.png'))\n",
        "np.random.shuffle(data_list)\n",
        "\n",
        "# define the percentage of the train/val\n",
        "perc_train = 0.8\n",
        "\n",
        "# actually create the two lists\n",
        "train_list = data_list[:int(perc_train*len(data_list))]\n",
        "val_list = data_list[int(perc_train*len(data_list)):]\n",
        "\n",
        "print(\"Training data:\", len(train_list))\n",
        "print(\"Validation data:\", len(val_list))"
      ],
      "metadata": {
        "id": "nKkqTLBmn3D7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can define two instances of the class `CustomDataGen`."
      ],
      "metadata": {
        "id": "yyT7fLmuNpBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = CustomDataGen(data_list=train_list, num_classes=4, batch_size=32, input_size=(224, 224, 3), shuffle=True)\n",
        "val_ds = CustomDataGen(data_list=val_list, num_classes=4, batch_size=32, input_size=(224, 224, 3), shuffle=True)"
      ],
      "metadata": {
        "id": "MPLYzlhxoARE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model architecture\n",
        "It's time to define the architecture of our *Convolutional Neural Network* (CNN), and we have two options:\n",
        "\n",
        "1.   Defining our **own architecture**.\n",
        "2.   Using one of the architecture proposed in the literature.  \n",
        "\n",
        "In our exercitation, we use the `MobileNet` CNN. We will use this architecture **pre-trained** on the `Imagenet` dataset (we are going to download the weights of the network from the official storage).\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lDJaJ9lSSqtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Our model\n",
        "model = tf.keras.applications.MobileNet(\n",
        "    input_shape=None,\n",
        "    alpha=1.0,\n",
        "    depth_multiplier=1,\n",
        "    dropout=0.001,\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation=\"softmax\"\n",
        "    )"
      ],
      "metadata": {
        "id": "ImPF3vGHhm58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the pre-trained model has 1000 classes, i.e. the final dense layer has 1000 neurons, while in our classification task we have only 4 classes.\n",
        "\n",
        "We need to adapt the architecture. We can remove the last layer and create a new dense layer with only 4 neurons."
      ],
      "metadata": {
        "id": "kyTIVjtv1f3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a layer where input is the output of the second last layer\n",
        "output = Dense(4, activation='softmax', name='predictions')(model.layers[-2].output)\n",
        "\n",
        "# Then create the corresponding model\n",
        "model = Model(model.input, output)"
      ],
      "metadata": {
        "id": "-D9sdfL-1THp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we define: \n",
        "\n",
        "*   How many epochs\n",
        "*   weights saving\n",
        "*   optimizer\n",
        "*   loss function\n",
        "*   metric to be used to check performance of the network\n",
        "\n"
      ],
      "metadata": {
        "id": "BaOFM9KxbTop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "\n",
        "callbacks = [\n",
        "    # to save the model after every epoch\n",
        "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n",
        "    # logging\n",
        "    tf.keras.callbacks.TensorBoard(log_dir=\"logs\", write_graph=True, write_images=False, update_freq=\"epoch\",)\n",
        "]\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.SGD(1e-3),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ],
      "metadata": {
        "id": "hD_8QfGEhvfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training\n",
        "If the training is too slow, remember to run the code on a machine equipped with a GPU.\n",
        "\n",
        "On Colab, click on **Runtime → Change Runtime type → GPU** (from the drop-down menu)\n",
        "\n",
        "We can further improve the load of images, setting workers > 1.\n",
        "Object sequence is a **safer way** to do **multiprocessing**. This structure guarantees that the network **will only train once on each sample per epoch** which is not the case with generators."
      ],
      "metadata": {
        "id": "BargpIWIbsft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds, workers=10\n",
        ")"
      ],
      "metadata": {
        "id": "Bt6J16Xbhzir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to use the CNN on single images"
      ],
      "metadata": {
        "id": "aYNpfwmToLiK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly, we have to define the function `get_class_name` to get the name of the label."
      ],
      "metadata": {
        "id": "Plr-kHjtsEAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class_name(label):\n",
        "    if label == 0:\n",
        "        return 'triangle'\n",
        "    elif label == 1:\n",
        "        return 'rectangle'\n",
        "    elif label == 2:\n",
        "        return 'square'\n",
        "    elif label == 3:\n",
        "        return 'rhombus'\n",
        "    else:\n",
        "        raise(NotImplementedError)"
      ],
      "metadata": {
        "id": "wVUL-TXk70ZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict the class of a single image.\n",
        "\n",
        "We open the image through the **OpenCV** library.\n",
        "\n",
        "**Tools**:\n",
        "\n",
        "*   `cv2.imread()`: open an image\n",
        "*   `cv2.resize()`: resize an image\n",
        "*   `np.asarray(..., dtype=...)`: convert the input to an array, with a specific data type\n",
        "\n",
        "**NB**: **input values must be float**, not integers!\n",
        "\n"
      ],
      "metadata": {
        "id": "adaUOT9p8vaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# load the (trained!) model\n",
        "model_trained = keras.models.load_model('/content/save_at_5.h5')\n",
        "\n",
        "# load an image\n",
        "image_path = '/content/Euclid_dataset_DL/triangle/0_triangle.png'\n",
        "image_path = '/content/Euclid_dataset_DL/rhombus/0_rhombus.png'\n",
        "img = cv2.imread(image_path, 1)\n",
        "\n",
        "# REMEMBER TO APPLY THE VERY SAME PROCEDURE USED DURING TRAINING!!\n",
        "\n",
        "# BGR -> RGB\n",
        "img = img[..., ::-1]\n",
        "# resize to 224x224\n",
        "img = cv2.resize(img, dsize=(224, 224))\n",
        "# uint8 -> float32\n",
        "img = np.asarray(img, dtype=np.float32)\n",
        "# image normalization\n",
        "img /= 255.\n",
        "\n",
        "# check the image shape\n",
        "print(img.shape)\n",
        "# add one dimension (the batch at the \"beginning\")\n",
        "img = np.expand_dims(img, 0)\n",
        "# check the final shape\n",
        "print(img.shape)\n",
        "\n",
        "# predict\n",
        "prediction = model_trained.predict(img)\n",
        "\n",
        "print('Predicted: {}'.format(prediction))\n",
        "print('Predicted: {}'.format(get_class_name(np.argmax(prediction[0]))))"
      ],
      "metadata": {
        "id": "DAP98dH58A_E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}